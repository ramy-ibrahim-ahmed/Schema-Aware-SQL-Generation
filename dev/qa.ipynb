{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d01f33",
   "metadata": {},
   "source": [
    "## Prepare NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5595dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "class GeminiNLP:\n",
    "    def __init__(self, gemini_client: genai):\n",
    "        self.genai = gemini_client\n",
    "\n",
    "    def chat(self, model_name, instructions, messages):\n",
    "        model = self.genai.GenerativeModel(\n",
    "            model_name=model_name, system_instruction=instructions\n",
    "        )\n",
    "        response = model.generate_content(messages)\n",
    "        return response.text\n",
    "\n",
    "    def struct_output(self, model_name, instructions, messages, structure):\n",
    "        model = self.genai.GenerativeModel(\n",
    "            model_name=model_name, system_instruction=instructions\n",
    "        )\n",
    "        response = model.generate_content(\n",
    "            contents=messages,\n",
    "            generation_config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": structure,\n",
    "            },\n",
    "        )\n",
    "        return structure.model_validate_json(response.text)\n",
    "\n",
    "    def func_call(self, model_name, messages, instructions, func):\n",
    "        model = self.genai.GenerativeModel(\n",
    "            model_name=model_name, system_instruction=instructions\n",
    "        )\n",
    "        try:\n",
    "            response = model.generate_content(messages, tools=[func])\n",
    "            call = response.candidates[0].content.parts[0].function_call\n",
    "\n",
    "            if call:\n",
    "                try:\n",
    "                    result = func(**call.args)\n",
    "                    return result\n",
    "                except Exception as e:\n",
    "                    args_dict = dict(call.args)\n",
    "                    return f\"Error when calling {call.name} with args {args_dict}: {e}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error during model generation: {e}\"\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc761713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_embeddings(vectors: list[list[float]]):\n",
    "    return [\n",
    "        (vec / np.linalg.norm(vec)) if np.linalg.norm(vec) != 0 else vec\n",
    "        for vec in vectors\n",
    "    ]\n",
    "\n",
    "\n",
    "class CohereEmbeddings:\n",
    "    def __init__(self, cohere_client):\n",
    "        self.cohere_client = cohere_client\n",
    "\n",
    "    async def embed(\n",
    "        self,\n",
    "        list_of_text: list[str],\n",
    "        model_name=\"embed-v4.0\",\n",
    "        batch_size=10,\n",
    "    ) -> list[list[float]]:\n",
    "        vectors = []\n",
    "        for i in range(0, len(list_of_text), batch_size):\n",
    "            batch = list_of_text[i : i + batch_size]\n",
    "            response = await self.cohere_client.embed(\n",
    "                texts=batch,\n",
    "                model=model_name,\n",
    "                input_type=\"search_document\",\n",
    "                embedding_types=[\"float\"],\n",
    "                output_dimension=1024,\n",
    "            )\n",
    "            batch_vectors = response.embeddings.float\n",
    "            normalized = normalize_embeddings(batch_vectors)\n",
    "            vectors.extend(normalized)\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a58bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from cohere import AsyncClientV2\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyChTcVwL9R2wWC6GnYeRI1pE4BDaHoIYLU\")\n",
    "nlp = GeminiNLP(gemini_client=genai)\n",
    "\n",
    "cohere_client = AsyncClientV2(api_key=\"oIbnS15GCHU7Q7QJ8gMSWlsSxxaangk8WGsUiDac\")\n",
    "embedding = CohereEmbeddings(cohere_client=cohere_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24179ea8",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604d8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "\n",
    "class ChromaProvider:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.client = None\n",
    "\n",
    "    def connect(self):\n",
    "        self.client = chromadb.PersistentClient(path=self.path)\n",
    "\n",
    "    def create_collection(self, name):\n",
    "        self.client.create_collection(\n",
    "            name=name,\n",
    "            configuration={\"hnsw\": {\"space\": \"cosine\", \"ef_construction\": 200}},\n",
    "        )\n",
    "\n",
    "    def add_points(self, collection_name, ids, embeddings, metadata):\n",
    "        collection = self.client.get_collection(name=collection_name)\n",
    "        collection.add(ids=ids, embeddings=embeddings, metadatas=metadata)\n",
    "\n",
    "    def semantic_search(self, collection_name, vector, top_k):\n",
    "        collection = self.client.get_collection(name=collection_name)\n",
    "        results = collection.query(query_embeddings=vector, n_results=top_k)\n",
    "        return results[\"metadatas\"]\n",
    "\n",
    "    def metadata_filter(self, collection_name, key, value):\n",
    "        collection = self.client.get_collection(name=collection_name)\n",
    "        results = collection.get(where={key: value})\n",
    "        return results[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2679cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"data/qa.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91da113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [f\"id_{i+1}\" for i in range(len(data))]\n",
    "text_chunks = [chunk[\"text\"] for chunk in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5afa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "embeddings_list = list()\n",
    "for i in range(0, len(text_chunks), 20):\n",
    "    batch = text_chunks[i : i + 20]\n",
    "    batch_embeddings = await embedding.embed(batch)\n",
    "    embeddings_list.extend(batch_embeddings)\n",
    "    await asyncio.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef67b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = ChromaProvider(path=\"chromadb\")\n",
    "vectordb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684fc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.create_collection(\"sales_qa_2\")\n",
    "vectordb.add_points(\"sales_qa_2\", ids, embeddings_list, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bea31",
   "metadata": {},
   "source": [
    "## Agentic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e067113",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fb1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PLAN = \"\"\"You are an AI agent that enhances youser question about an ERP system.\n",
    "Take user question and generate an Expanded question for a semantic search process.\n",
    "user question: {user_message}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT_SQL = \"\"\"You atr a SQL agent, You will take user question with relevant examples to take inspiration from.\n",
    "You need to use wanted columns only to generate the SQL statement. Make sure that your query follows **Oracle 11g**.\n",
    "\n",
    "User Question: {user_message}\n",
    "\n",
    "Examples:\n",
    "\n",
    "{examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ce89a",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666c249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: list[str] = Field(\n",
    "        ..., description=\"Expanded ERP question.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SQL(BaseModel):\n",
    "    sql: str = Field(..., description=\"Correct Oracle 11g SQL statement\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_message: str\n",
    "    queries: Queries\n",
    "    schema: str\n",
    "    sql_query: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bce20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner(state: State) -> State:\n",
    "    user_message = state.get(\"user_message\", \"\")\n",
    "    prompt = PROMPT_PLAN.format(user_message=user_message)\n",
    "    response = nlp.struct_output(\n",
    "        \"gemini-2.5-flash\",\n",
    "        \"you are an sql generation planner agent\",\n",
    "        prompt,\n",
    "        Queries,\n",
    "    )\n",
    "    return {\"queries\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77a3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search(state: State) -> State:\n",
    "    queries = state.get(\"queries\").queries\n",
    "    vectors = await embedding.embed(queries)\n",
    "\n",
    "    results = vectordb.semantic_search(\"sales_qa\", vectors, 5)\n",
    "    flatten = [item for sublist in results for item in sublist]\n",
    "\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for res in flatten:\n",
    "        key = res[\"text\"]\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique.append(res)\n",
    "\n",
    "    schema_list = [\n",
    "        f\"Question: {res['text']}\\nSQL Statement: {res['sql']}\" for res in unique\n",
    "    ]\n",
    "    schema_text = \"\\n\\n---\\n\\n\".join(schema_list)\n",
    "\n",
    "    return {\"schema\": \"Examples\\n\\n\" + schema_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql(state: State) -> State:\n",
    "    user_message = state.get(\"user_message\")\n",
    "    schema = state.get(\"schema\")\n",
    "    prompt = PROMPT_SQL.format(user_message=user_message, examples=schema)\n",
    "    response = nlp.struct_output(\n",
    "        \"gemini-2.5-flash\",\n",
    "        \"you are an Oracle 11g sql generation agent\",\n",
    "        prompt,\n",
    "        SQL,\n",
    "    )\n",
    "    return {\"sql_query\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621a2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"plan\", planner)\n",
    "workflow.add_node(\"search\", search)\n",
    "workflow.add_node(\"sql\", sql)\n",
    "\n",
    "workflow.set_entry_point(\"plan\")\n",
    "workflow.add_edge(\"plan\", \"search\")\n",
    "workflow.add_edge(\"search\", \"sql\")\n",
    "workflow.add_edge(\"sql\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7812c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': {'queries': Queries(queries=['ما هو صافي الربح للشهر الماضي؟', 'كم كان الربح الإجمالي للشهر السابق؟', 'عرض تقرير الربح والخسارة للشهر الأخير.', 'استعلام عن أداء الربحية للشهر المنصرم.', 'ما هي إيرادات ومصروفات الشهر الماضي؟', 'أرغب في رؤية ملخص الربح التشغيلي للشهر الماضي.', 'معرفة الأرباح المحققة خلال آخر فترة محاسبية مغلقة.'])}}\n",
      "{'search': {'schema': 'Examples\\n\\nQuestion: Calculate the profit margin for each item sold in the last year by subtracting total purchase cost from sales amount, using sales and purchase details.\\nSQL Statement: SELECT SBD.ITM_CODE AS \"Item Code\", SUM(SBD.ITM_TOTL_AMT - SBD.ITM_TOTL_STK_CST) AS \"Total Profit\", (SUM(SBD.ITM_TOTL_AMT - SBD.ITM_TOTL_STK_CST) / SUM(SBD.ITM_TOTL_AMT)) * 100 AS \"Profit Margin %\" FROM SALES_BILL_DTL_AI_VW SBD WHERE EXISTS (SELECT 1 FROM PURCHS_BILL_DTL_AI_VW PBD WHERE PBD.ITM_CODE = SBD.ITM_CODE) AND SBD.YR_NO = EXTRACT(YEAR FROM SYSDATE) - 1 GROUP BY SBD.ITM_CODE HAVING SUM(SBD.ITM_TOTL_AMT) > 0 ORDER BY \"Profit Margin %\" DESC;\\n\\n---\\n\\nQuestion: Compute the profit margin for each finished product in work orders completed in the last month, where profit margin is (total_actual_cost / total_standard_cost) * 100.\\nSQL Statement: SELECT ITEM_CODE, WORK_ORDER_NO, (TOTAL_ACTUAL_COST / NULLIF(TOTAL_STANDARD_COST, 0)) * 100 AS profit_margin_pct\\nFROM MRP_WORK_ORDER_AI_VW\\nWHERE ITEM_CLASS = 1\\nAND WORK_ORDER_STATUS = 3\\nAND WORK_ORDER_DATE >= DATEADD(MONTH, -1, CURRENT_DATE)\\nORDER BY profit_margin_pct DESC;\\n\\n---\\n\\nQuestion: Calculate the net profit for each work order by subtracting total actual cost from total sales amount of the produced items, joining work orders, sales details, and inventory.\\nSQL Statement: SELECT MWO.WORK_ORDER_NO, MWO.ITEM_CODE, (SUM(SBD.ITM_TOTL_AMT) - MWO.TOTAL_ACTUAL_COST) AS Net_Profit FROM MRP_WORK_ORDER_AI_VW MWO INNER JOIN INV_V_ITM_MOVMNT_AI IVM ON MWO.ITEM_CODE = IVM.ITEM_CODE AND MWO.WORK_ORDER_STATUS = 3 INNER JOIN SALES_BILL_DTL_AI_VW SBD ON IVM.ITEM_CODE = SBD.ITM_CODE AND IVM.DOCUMENT_DATE = SBD.DOC_DATE WHERE MWO.ITEM_CLASS = 1 GROUP BY MWO.WORK_ORDER_NO, MWO.ITEM_CODE;\\n\\n---\\n\\nQuestion: Generate a report of profit and loss accounts showing total debits and credits for the fiscal period.\\nSQL Statement: SELECT AC_L_NM, SUM(DR_AMT_L) AS total_debits, SUM(CR_AMT_L) AS total_credits FROM GLS_PST_AI_VW WHERE AC_TYP = 0 GROUP BY AC_L_NM;\\n\\n---\\n\\nQuestion: List the top 5 vendors by total purchase amount in local currency for purchases made in the last quarter, including their names.\\nSQL Statement: SELECT VNDR_NM, SUM(TOTL_BILL_AMT_LOCAL) AS total_purchases FROM PURCHS_BILL_MST_AI_VW WHERE DOC_DATE >= DATEADD(QUARTER, -1, GETDATE()) GROUP BY VNDR_NM ORDER BY total_purchases DESC LIMIT 5;\\n\\n---\\n\\nQuestion: Provide a summary of currency differences in financial postings for foreign currency transactions in the last year.\\nSQL Statement: SELECT CUR_CODE, SUM(DR_AMT_F - DR_AMT_L) AS debit_diff, SUM(CR_AMT_F - CR_AMT_L) AS credit_diff FROM GLS_PST_AI_VW WHERE IS_CRNCY_DFRNC = 1 AND DOC_DATE >= DATEADD(YEAR, -1, GETDATE()) GROUP BY CUR_CODE;\\n\\n---\\n\\nQuestion: Calculate the inventory turnover ratio for each item, using average inventory and cost of goods sold from sales details.\\nSQL Statement: WITH avg_inv AS (SELECT ITEM_CODE, AVG(AVAILABLE_QUANTITY) AS avg_quantity FROM INV_V_ITM_MOVMNT_AI GROUP BY ITEM_CODE), cogs AS (SELECT ITM_CODE, SUM(ITM_TOTL_STK_CST) AS total_cogs FROM SALES_BILL_DTL_AI_VW GROUP BY ITM_CODE) SELECT avg_inv.ITEM_CODE, total_cogs / avg_quantity AS turnover_ratio FROM avg_inv INNER JOIN cogs ON avg_inv.ITEM_CODE = cogs.ITM_CODE;\\n\\n---\\n\\nQuestion: What are the debit and credit amounts in local currency for each account type in the general ledger postings, for documents dated in the last quarter?\\nSQL Statement: SELECT AC_TYP, SUM(DR_AMT_L) AS total_debit_local, SUM(CR_AMT_L) AS total_credit_local FROM GLS_PST_AI_VW WHERE DOC_DATE >= DATE_SUB(CURDATE(), INTERVAL 3 MONTH) GROUP BY AC_TYP;\\n\\n---\\n\\nQuestion: What is the total credit amount for bank accounts (AC_DTL_TYP = 2) in foreign currency for transactions in the last year?\\nSQL Statement: SELECT SUM(CR_AMT_F) AS total_credit_foreign FROM GLS_PST_AI_VW WHERE AC_DTL_TYP = 2 AND DOC_DATE >= DATEADD(YEAR, -1, GETDATE());\\n\\n---\\n\\nQuestion: List the top 5 vendors by total purchase amount in local currency from purchase bills, including vendor name and total amount, for purchases made in the last quarter.\\nSQL Statement: SELECT VNDR_NM AS vendor_name, SUM(TOTL_BILL_AMT_LOCAL) AS total_purchase FROM PURCHS_BILL_MST_AI_VW WHERE DOC_DATE >= DATEADD(QUARTER, -1, GETDATE()) GROUP BY VNDR_NM ORDER BY total_purchase DESC LIMIT 5;\\n\\n---\\n\\nQuestion: List all employees with their total debit and credit transactions if they appear in the general ledger as employees.\\nSQL Statement: SELECT e.EMP_L_NM, SUM(g.DR_AMT_L) AS total_debit, SUM(g.CR_AMT_L) AS total_credit FROM GNR_EMP_AI_VW e JOIN GLS_PST_AI_VW g ON e.EMP_NO = g.AC_CODE_DTL WHERE g.AC_DTL_TYP = 7 GROUP BY e.EMP_L_NM;\\n\\n---\\n\\nQuestion: Calculate the gross profit for each item sold in sales bills by subtracting total stock cost from total price after discounts.\\nSQL Statement: SELECT ITM_CODE AS item_code, SUM(ITM_TOTL_PRICE - ITM_TOTL_DSCNT_AMT - ITM_TOTL_STK_CST) AS gross_profit FROM SALES_BILL_DTL_AI_VW GROUP BY ITM_CODE;\\n\\n---\\n\\nQuestion: List all completed work orders for finished products along with their actual cost.\\nSQL Statement: SELECT WORK_ORDER_NO, TOTAL_ACTUAL_COST FROM MRP_WORK_ORDER_AI_VW WHERE WORK_ORDER_STATUS = 3 AND ITEM_CLASS = 1;'}}\n",
      "{'sql': {'sql_query': SQL(sql=\"SELECT SUM(ITM_TOTL_AMT - ITM_TOTL_STK_CST) AS Total_Profit_Last_Month FROM SALES_BILL_DTL_AI_VW WHERE DOC_DATE >= ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -1) AND DOC_DATE < TRUNC(SYSDATE, 'MM')\")}}\n"
     ]
    }
   ],
   "source": [
    "async for event in graph.astream({\"user_message\": \"عايز اعرف الربح اخر شهر\"}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT SUM(ITM_TOTL_AMT - ITM_TOTL_STK_CST) AS Total_Profit_Last_Month FROM SALES_BILL_DTL_AI_VW WHERE DOC_DATE >= ADD_MONTHS(SYSDATE, -1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300a860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6169ca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'مرحباً، أنا رامي.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class GeminiChatEnums(Enum):\n",
    "    ROLE = \"role\"\n",
    "    CONTENT = \"parts\"\n",
    "    USER = \"user\"\n",
    "    MODEL = \"model\"\n",
    "\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyD9bEgveLP0H9Y_8_PQFWCdyH4YgO6FDrY\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "\n",
    "def chat(model_name: str, instructions: str, messages: dict):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=model_name, system_instruction=instructions\n",
    "    )\n",
    "    response = model.generate_content(messages)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        GeminiChatEnums.ROLE.value: GeminiChatEnums.USER.value,\n",
    "        GeminiChatEnums.CONTENT.value: \"Hi I am Ramy\",\n",
    "    }\n",
    "]\n",
    "instruction = \"You are an Arabic Translator. translate user input\"\n",
    "res = chat(model_name, instruction, messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(text='لاعب كرة قدم قال لمدربه: أنا ما ألعب إلا على الواقف! رد المدرب: خلاص خليك حارس مرمى.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "def struct_output(\n",
    "    model_name: str, instructions: str, content: str, structure: BaseModel\n",
    "):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=model_name, system_instruction=instructions\n",
    "    )\n",
    "    response = model.generate_content(\n",
    "        contents=content,\n",
    "        generation_config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": structure,\n",
    "        },\n",
    "    )\n",
    "    return structure.model_validate_json(response.text)\n",
    "\n",
    "\n",
    "res = struct_output(model_name, \"tell a Joke in Arabic about the topic.\", \"football\", Joke)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401f1d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a: int, b: int):\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def func_call(model_name: str, content: str, instructions: str, func):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=model_name, system_instruction=instructions\n",
    "    )\n",
    "    try:\n",
    "        response = model.generate_content([content], tools=[func])\n",
    "        call = response.candidates[0].content.parts[0].function_call\n",
    "\n",
    "        if call:\n",
    "            try:\n",
    "                result = func(**call.args)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                args_dict = dict(call.args)\n",
    "                return f\"Error when calling {call.name} with args {args_dict}: {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during model generation: {e}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "res = func_call(model_name, \"add 4 and 90\", \"call function\", add)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e762efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_func(call)\n",
    "\n",
    "if function_call:\n",
    "    print(\n",
    "        f\"Assistant: [Calling function '{function_call.name}' with args {function_call.args}]\"\n",
    "    )\n",
    "\n",
    "    # Step 2: Execute the function\n",
    "    if function_call.name == \"add\":\n",
    "        result = add(**function_call.args)\n",
    "        print(f\"Tool ({function_call.name}): {result}\")\n",
    "\n",
    "        # Step 3: Prepare the function response and get the final model response\n",
    "        # Build the content history\n",
    "        contents = [\n",
    "            genai.protos.Content(\n",
    "                parts=[genai.protos.Part(text=user_query)], role=\"user\"\n",
    "            ),\n",
    "            genai.protos.Content(\n",
    "                parts=[genai.protos.Part(function_call=function_call)], role=\"model\"\n",
    "            ),\n",
    "            genai.protos.Content(\n",
    "                parts=[\n",
    "                    genai.protos.Part(\n",
    "                        function_response=genai.protos.FunctionResponse(\n",
    "                            name=function_call.name,\n",
    "                            response={\"result\": str(result)},  # Response must be a dict\n",
    "                        )\n",
    "                    )\n",
    "                ],\n",
    "                role=\"user\",  # Function responses are sent as 'user' role\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Generate the final response from the model\n",
    "        final_response = model.generate_content(contents, tools=[add])\n",
    "\n",
    "        # Print the final assistant response\n",
    "        if final_response.candidates and final_response.candidates[0].content.parts:\n",
    "            print(\"Assistant: \" + final_response.candidates[0].content.parts[0].text)\n",
    "else:\n",
    "    # If no function call, just print the direct response\n",
    "    if response.candidates and response.candidates[0].content.parts:\n",
    "        print(\"Assistant: \" + response.candidates[0].content.parts[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
